{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"RustyBalancer A high-performance, auto-scaling load balancer implemented in Rust. Overview This project provides a robust load balancing solution with automatic scaling capabilities. Built with Rust, it offers efficient resource management and optimal request distribution for containerized applications. Key features: Dynamic load balancing Automatic scaling based on real-time metrics Container-native architecture High performance and low resource footprint Contributing Feel free to submit issues, fork the repository, and send pull requests. For major changes, please open an issue first to discuss what you would like to change.","title":"Home"},{"location":"#rustybalancer","text":"A high-performance, auto-scaling load balancer implemented in Rust.","title":"RustyBalancer"},{"location":"#overview","text":"This project provides a robust load balancing solution with automatic scaling capabilities. Built with Rust, it offers efficient resource management and optimal request distribution for containerized applications. Key features: Dynamic load balancing Automatic scaling based on real-time metrics Container-native architecture High performance and low resource footprint","title":"Overview"},{"location":"#contributing","text":"Feel free to submit issues, fork the repository, and send pull requests. For major changes, please open an issue first to discuss what you would like to change.","title":"Contributing"},{"location":"components/","text":"Overview of the main components This project implements a sophisticated deployment agent and load balancer system in Rust. It manages Docker containers, monitors their performance, and dynamically adjusts the container pool based on load and performance metrics. This diagram provides a comprehensive overview of all components, each of which represents an active container within the system landscape established during the deployment process.","title":"Index"},{"location":"components/#overview-of-the-main-components","text":"This project implements a sophisticated deployment agent and load balancer system in Rust. It manages Docker containers, monitors their performance, and dynamically adjusts the container pool based on load and performance metrics. This diagram provides a comprehensive overview of all components, each of which represents an active container within the system landscape established during the deployment process.","title":"Overview of the main components"},{"location":"env/","text":"Environment Variables Configuration This page provides a comprehensive overview of the environment variables used in our application. These variables control various aspects of the system, including Docker configuration, networking, scaling, and performance metrics. Docker & Worker Variable Description DOCKER_IMAGE Docker image for the worker TARGET_PORT Application port in container DOCKER_HOST Docker daemon URL DOCKER_SOCKET_VOLUME Docker socket file path Network Ports Variable Description HOST_PORT_WS_DEPLOYMENT_AGENT WebSocket port for deployment agent HOST_PORT_WS_BALANCER WebSocket port for balancer HOST_PORT_HTTP_DEPLOYMENT_AGENT HTTP port for deployment agent HOST_PORT_HTTP_BALANCER HTTP port for balancer PORT_DASHBOARD Dashboard port Application & Redis Variable Description DEFAULT_CONTAINER Default container count at startup APP_IDENTIFIER Unique application ID REDIS_PORT Redis server port REDIS_HOST Redis server hostname/IP REDIS_INSIGHT_PORT Redis Insight tool port Load & Scaling Variable Description HIGH_LOAD_THRESHOLD High load threshold (%) LOW_LOAD_THRESHOLD Low load threshold (%) CRITICAL_LOAD_THRESHOLD Critical load threshold (%) MAX_CONTAINERS Maximum container count COOLDOWN_PERIOD Cooldown between scaling actions (s) SCALE_STEP Containers to add/remove per scaling action SCALE_CHECK_PERIOD Interval for scaling checks (min) Performance Evaluation Variable Description CPU_WEIGHT CPU usage weight MEMORY_WEIGHT Memory usage weight NETWORK_WEIGHT Network usage weight AVAILABILITY_WEIGHT Availability weight Other Settings Variable Description HISTORY_SIZE Number of metrics to store BEST_TIME_WINDOW Time window for best performance (s) EMA_ALPHA Smoothing factor for EMA REQUEST_TIMEOUT HTTP request timeout (s) CACHE_CAPACITY Maximum cache entries Note: Changes to environment variables require a system restart.","title":"Environment"},{"location":"env/#environment-variables-configuration","text":"This page provides a comprehensive overview of the environment variables used in our application. These variables control various aspects of the system, including Docker configuration, networking, scaling, and performance metrics.","title":"Environment Variables Configuration"},{"location":"env/#docker-worker","text":"Variable Description DOCKER_IMAGE Docker image for the worker TARGET_PORT Application port in container DOCKER_HOST Docker daemon URL DOCKER_SOCKET_VOLUME Docker socket file path","title":"Docker &amp; Worker"},{"location":"env/#network-ports","text":"Variable Description HOST_PORT_WS_DEPLOYMENT_AGENT WebSocket port for deployment agent HOST_PORT_WS_BALANCER WebSocket port for balancer HOST_PORT_HTTP_DEPLOYMENT_AGENT HTTP port for deployment agent HOST_PORT_HTTP_BALANCER HTTP port for balancer PORT_DASHBOARD Dashboard port","title":"Network Ports"},{"location":"env/#application-redis","text":"Variable Description DEFAULT_CONTAINER Default container count at startup APP_IDENTIFIER Unique application ID REDIS_PORT Redis server port REDIS_HOST Redis server hostname/IP REDIS_INSIGHT_PORT Redis Insight tool port","title":"Application &amp; Redis"},{"location":"env/#load-scaling","text":"Variable Description HIGH_LOAD_THRESHOLD High load threshold (%) LOW_LOAD_THRESHOLD Low load threshold (%) CRITICAL_LOAD_THRESHOLD Critical load threshold (%) MAX_CONTAINERS Maximum container count COOLDOWN_PERIOD Cooldown between scaling actions (s) SCALE_STEP Containers to add/remove per scaling action SCALE_CHECK_PERIOD Interval for scaling checks (min)","title":"Load &amp; Scaling"},{"location":"env/#performance-evaluation","text":"Variable Description CPU_WEIGHT CPU usage weight MEMORY_WEIGHT Memory usage weight NETWORK_WEIGHT Network usage weight AVAILABILITY_WEIGHT Availability weight","title":"Performance Evaluation"},{"location":"env/#other-settings","text":"Variable Description HISTORY_SIZE Number of metrics to store BEST_TIME_WINDOW Time window for best performance (s) EMA_ALPHA Smoothing factor for EMA REQUEST_TIMEOUT HTTP request timeout (s) CACHE_CAPACITY Maximum cache entries Note: Changes to environment variables require a system restart.","title":"Other Settings"},{"location":"publications/","text":"Preview Download Towards Practical and Scalable Strategies for the Online Load Balancing Problem in distributed systems","title":"Publications"},{"location":"publications/#preview","text":"","title":"Preview"},{"location":"publications/#_1","text":"","title":""},{"location":"publications/#download","text":"Towards Practical and Scalable Strategies for the Online Load Balancing Problem in distributed systems","title":"Download"},{"location":"setup/","text":"Quick Start Clone the repository Choose one of the following methods: Basic clone (core codebase only): git clone https://github.com/mxmueller/RustyBalancer.git Clone with submodules (recommended for development/testing): git clone --recursive https://github.com/mxmueller/RustyBalancer.git Then navigate to the project directory: cd RustyBalancer Run the setup script cd jobs ./setup.sh Configure the .env file Open the .env file in the project root directory. Set Docker image and port In the .env file, set your desired Docker image and its corresponding port. For example: DOCKER_IMAGE=your-docker-image TARGET_PORT=your-image-port Example: DOCKER_IMAGE=traefik/whoami TARGET_PORT=80 Note: Currently, only images using a single port are supported. The specified image will be distributed and scaled across workers. Run RustyBalancer cd jobs ./run.sh -e dev # For dev Enviroment If the Plug-and-Play variant was selected in the setup, the artifacts are available as follows: URL Description http://localhost:2548 Load balancer page where the pages hosted in the workers can be accessed http://localhost:2550/stats Raw data of stats for all containers. Updated when the route is called. http://localhost:8501 Application dashboard (Only in the Dev variant) http://localhost:5540 Redis Insights (Only in the Dev variant) Important! When changing the image or if environment changes are not loading, you must: Stop all running Containers Either manually remove all containers affected by the environment variable changes. Or, if the image has been changed, remove all containers with the APP_IDENTIFIER from the environment. Alternatively, you can run reset.sh located in the ./jobs/ directory, which performs these actions automatically. After that u can re-run with run.sh Detailed Explanation Repository Cloning Options Basic Clone: This method clones only the main repository. It's sufficient if you only need the core codebase. git clone https://github.com/mxmueller/RustyBalancer.git Clone with Submodules (recommended for development/testing): This method clones the repository with its submodules, including the test suite for automated testing. bash git clone --recursive https://github.com/mxmueller/RustyBalancer.git The submodule rustybalancer-test-suite includes automated test cases for HTTP Stress Tests and QR Code Generator Stress Tests. Prerequisites Docker must be installed. Download from Docker's official site . For macOS/Windows: docker-compose is required. For Linux: docker compose (Docker CLI plugin) is preferred. Configuration Files docker-compose.yaml : Production environment setup. Includes redis, deployment-agent, dashboard, and balancer services. docker-compose.dev.yaml : Development environment with additional tools. Includes all production services plus redis-insight and more environment variables for testing. docker-compose.slim.yaml : Lightweight setup for resource-constrained environments. Excludes dashboard and redis-insight services. Environment Setup The setup.sh script generates a .env file with your RustyBalancer configuration. Running RustyBalancer Use the run.sh script in the jobs directory: Production: ./run.sh -e prod Development: ./run.sh -e dev Slim: ./run.sh -e slim The script automatically selects docker compose or docker-compose based on your system. Docker Group (if needed) Add your user to the Docker group: sudo usermod -aG docker $USER","title":"Setup"},{"location":"setup/#quick-start","text":"","title":"Quick Start"},{"location":"setup/#clone-the-repository","text":"Choose one of the following methods: Basic clone (core codebase only): git clone https://github.com/mxmueller/RustyBalancer.git Clone with submodules (recommended for development/testing): git clone --recursive https://github.com/mxmueller/RustyBalancer.git Then navigate to the project directory: cd RustyBalancer","title":"Clone the repository"},{"location":"setup/#run-the-setup-script","text":"cd jobs ./setup.sh","title":"Run the setup script"},{"location":"setup/#configure-the-env-file","text":"Open the .env file in the project root directory.","title":"Configure the .env file"},{"location":"setup/#set-docker-image-and-port","text":"In the .env file, set your desired Docker image and its corresponding port. For example: DOCKER_IMAGE=your-docker-image TARGET_PORT=your-image-port Example: DOCKER_IMAGE=traefik/whoami TARGET_PORT=80 Note: Currently, only images using a single port are supported. The specified image will be distributed and scaled across workers.","title":"Set Docker image and port"},{"location":"setup/#run-rustybalancer","text":"cd jobs ./run.sh -e dev # For dev Enviroment If the Plug-and-Play variant was selected in the setup, the artifacts are available as follows: URL Description http://localhost:2548 Load balancer page where the pages hosted in the workers can be accessed http://localhost:2550/stats Raw data of stats for all containers. Updated when the route is called. http://localhost:8501 Application dashboard (Only in the Dev variant) http://localhost:5540 Redis Insights (Only in the Dev variant)","title":"Run RustyBalancer"},{"location":"setup/#important","text":"When changing the image or if environment changes are not loading, you must: Stop all running Containers Either manually remove all containers affected by the environment variable changes. Or, if the image has been changed, remove all containers with the APP_IDENTIFIER from the environment. Alternatively, you can run reset.sh located in the ./jobs/ directory, which performs these actions automatically. After that u can re-run with run.sh","title":"Important!"},{"location":"setup/#detailed-explanation","text":"","title":"Detailed Explanation"},{"location":"setup/#repository-cloning-options","text":"Basic Clone: This method clones only the main repository. It's sufficient if you only need the core codebase. git clone https://github.com/mxmueller/RustyBalancer.git Clone with Submodules (recommended for development/testing): This method clones the repository with its submodules, including the test suite for automated testing. bash git clone --recursive https://github.com/mxmueller/RustyBalancer.git The submodule rustybalancer-test-suite includes automated test cases for HTTP Stress Tests and QR Code Generator Stress Tests.","title":"Repository Cloning Options"},{"location":"setup/#prerequisites","text":"Docker must be installed. Download from Docker's official site . For macOS/Windows: docker-compose is required. For Linux: docker compose (Docker CLI plugin) is preferred.","title":"Prerequisites"},{"location":"setup/#configuration-files","text":"docker-compose.yaml : Production environment setup. Includes redis, deployment-agent, dashboard, and balancer services. docker-compose.dev.yaml : Development environment with additional tools. Includes all production services plus redis-insight and more environment variables for testing. docker-compose.slim.yaml : Lightweight setup for resource-constrained environments. Excludes dashboard and redis-insight services.","title":"Configuration Files"},{"location":"setup/#environment-setup","text":"The setup.sh script generates a .env file with your RustyBalancer configuration.","title":"Environment Setup"},{"location":"setup/#running-rustybalancer","text":"Use the run.sh script in the jobs directory: Production: ./run.sh -e prod Development: ./run.sh -e dev Slim: ./run.sh -e slim The script automatically selects docker compose or docker-compose based on your system.","title":"Running RustyBalancer"},{"location":"setup/#docker-group-if-needed","text":"Add your user to the Docker group: sudo usermod -aG docker $USER","title":"Docker Group (if needed)"},{"location":"tutorial/","text":"Tutorial Selection This section offers a rich collection of videos that serve as a comprehensive visual guide to understanding and implementing load balancers. These informative videos cover several crucial aspects of load balancing technology, providing viewers with a thorough understanding of their operations. The content begins with step-by-step instructions on how to configure and deploy a load balancer in various environments, ensuring a solid foundation for implementation. Viewers will then delve into an in-depth exploration of the essential artifacts and elements that compose a load balancer system, including both hardware and software components. The videos also demonstrate how load balancers adapt to fluctuating demands, showcasing their ability to efficiently distribute traffic across multiple servers. To round out the practical knowledge, multiple approaches to stress-testing load balancers are presented, offering valuable insights into performance under different scenarios and traffic patterns. Whether you're a beginner looking to grasp the fundamentals or an experienced professional seeking to optimize your infrastructure, these visual resources offer invaluable insights into the world of load balancing technology, from basic concepts to advanced implementations.","title":"Index"},{"location":"tutorial/#tutorial-selection","text":"This section offers a rich collection of videos that serve as a comprehensive visual guide to understanding and implementing load balancers. These informative videos cover several crucial aspects of load balancing technology, providing viewers with a thorough understanding of their operations. The content begins with step-by-step instructions on how to configure and deploy a load balancer in various environments, ensuring a solid foundation for implementation. Viewers will then delve into an in-depth exploration of the essential artifacts and elements that compose a load balancer system, including both hardware and software components. The videos also demonstrate how load balancers adapt to fluctuating demands, showcasing their ability to efficiently distribute traffic across multiple servers. To round out the practical knowledge, multiple approaches to stress-testing load balancers are presented, offering valuable insights into performance under different scenarios and traffic patterns. Whether you're a beginner looking to grasp the fundamentals or an experienced professional seeking to optimize your infrastructure, these visual resources offer invaluable insights into the world of load balancing technology, from basic concepts to advanced implementations.","title":"Tutorial Selection"},{"location":"components/balancer/","text":"Balancer Table of Contents Features System Architecture Configuration Dependencies Error and Logs Features Dynamic load balancing based on server scores Caching of static resources Asynchronous processing of HTTP requests Automatic reconnection to WebSocket with exponential backoff Periodic garbage collection for cache entries System Architecture The system consists of several interconnected modules: Main Application ( main.rs ) HTTP Server ( http.rs ) WebSocket Client ( socket.rs ) Unbounded Client ( client.rs ) Cache ( cache.rs ) Queue ( queue.rs ) Modules Main ( main.rs ) The entry point of the application. It sets up the shared state, initializes the UnboundedClient for outgoing requests, creates a cache for static resources, and spawns two main tasks: WebSocket connection to receive backend server updates HTTP server to handle incoming requests HTTP Server ( http.rs ) Implements the HTTP server that receives incoming requests and forwards them to the selected backend server. It uses a DynamicWeightedBalancer to choose the appropriate backend server for each request. Key features include: Caching of static resources Periodic updates of backend server weights Handling of both static and dynamic requests WebSocket Client ( socket.rs ) Maintains a WebSocket connection to a deployment agent to receive updates about available backend servers. It continuously attempts to reconnect in case of connection failures, with an exponential backoff strategy. Unbounded Client ( client.rs ) A custom HTTP client implementation that can handle a large number of concurrent requests. It uses a channel-based approach to queue requests and process them asynchronously. Cache ( cache.rs ) Implements a simple in-memory cache with TTL (Time To Live) for each entry. It includes a background task for garbage collection to remove expired entries. Queue ( queue.rs ) Defines the QueueItem struct representing a backend server and provides functionality to parse JSON data into a vector of QueueItem s. Configuration The application uses environment variables for configuration. Make sure to set the following variables: HOST_PORT_HTTP_BALANCER : Port for the HTTP server HOST_PORT_WS_DEPLOYMENT_AGENT : Port for the WebSocket connection to the deployment agent TARGET_PORT : Port of the backend servers CACHE_CAPACITY : Maximum number of items in the cache REQUEST_TIMEOUT : Timeout for outgoing requests (in seconds) Dependencies tokio : Asynchronous runtime hyper : HTTP client and server tokio-tungstenite : WebSocket client serde : Serialization and deserialization of JSON rand : Random number generation for the weighted balancer log and env_logger : Logging Error Handling and Logging The application uses the log crate for logging. It logs information about connections, errors, and important state changes. Make sure to initialize the logger in your environment to see the logs.","title":"Balancer"},{"location":"components/balancer/#balancer","text":"Table of Contents Features System Architecture Configuration Dependencies Error and Logs Features Dynamic load balancing based on server scores Caching of static resources Asynchronous processing of HTTP requests Automatic reconnection to WebSocket with exponential backoff Periodic garbage collection for cache entries System Architecture The system consists of several interconnected modules: Main Application ( main.rs ) HTTP Server ( http.rs ) WebSocket Client ( socket.rs ) Unbounded Client ( client.rs ) Cache ( cache.rs ) Queue ( queue.rs ) Modules Main ( main.rs ) The entry point of the application. It sets up the shared state, initializes the UnboundedClient for outgoing requests, creates a cache for static resources, and spawns two main tasks: WebSocket connection to receive backend server updates HTTP server to handle incoming requests HTTP Server ( http.rs ) Implements the HTTP server that receives incoming requests and forwards them to the selected backend server. It uses a DynamicWeightedBalancer to choose the appropriate backend server for each request. Key features include: Caching of static resources Periodic updates of backend server weights Handling of both static and dynamic requests WebSocket Client ( socket.rs ) Maintains a WebSocket connection to a deployment agent to receive updates about available backend servers. It continuously attempts to reconnect in case of connection failures, with an exponential backoff strategy. Unbounded Client ( client.rs ) A custom HTTP client implementation that can handle a large number of concurrent requests. It uses a channel-based approach to queue requests and process them asynchronously. Cache ( cache.rs ) Implements a simple in-memory cache with TTL (Time To Live) for each entry. It includes a background task for garbage collection to remove expired entries. Queue ( queue.rs ) Defines the QueueItem struct representing a backend server and provides functionality to parse JSON data into a vector of QueueItem s. Configuration The application uses environment variables for configuration. Make sure to set the following variables: HOST_PORT_HTTP_BALANCER : Port for the HTTP server HOST_PORT_WS_DEPLOYMENT_AGENT : Port for the WebSocket connection to the deployment agent TARGET_PORT : Port of the backend servers CACHE_CAPACITY : Maximum number of items in the cache REQUEST_TIMEOUT : Timeout for outgoing requests (in seconds) Dependencies tokio : Asynchronous runtime hyper : HTTP client and server tokio-tungstenite : WebSocket client serde : Serialization and deserialization of JSON rand : Random number generation for the weighted balancer log and env_logger : Logging Error Handling and Logging The application uses the log crate for logging. It logs information about connections, errors, and important state changes. Make sure to initialize the logger in your environment to see the logs.","title":"Balancer"},{"location":"components/dashboard/","text":"Overview The RustBalancer Dashboard is a Streamlit-based web interface for real-time monitoring of the load balancing system. Key Features Auto-refreshing data (every 5 seconds) Overview table with container metrics Pie charts for score distributions (CPU, Memory, Network, Availability) Bar charts for CPU and Memory scores Summary metrics and detailed container information Access The dashboard is accessible via web browser at http://localhost:8501 It's configured in docker-compose.dev.yml as part of the RustBalancer system Docker Setup dashboard: build: context: ./dashboard dockerfile: Dockerfile ports: - \"8501:8501\" environment: - DEPLOYMENT_URL=http://deployment-agent:${HOST_PORT_HTTP_DEPLOYMENT_AGENT}/stats depends_on: - deployment-agent - redis networks: - rust-network The dashboard automatically fetches and displays the latest data from the deployment agent, providing a comprehensive view of your RustBalancer system's performance.","title":"Dashboard"},{"location":"components/dashboard/#overview","text":"The RustBalancer Dashboard is a Streamlit-based web interface for real-time monitoring of the load balancing system.","title":"Overview"},{"location":"components/dashboard/#key-features","text":"Auto-refreshing data (every 5 seconds) Overview table with container metrics Pie charts for score distributions (CPU, Memory, Network, Availability) Bar charts for CPU and Memory scores Summary metrics and detailed container information","title":"Key Features"},{"location":"components/dashboard/#access","text":"The dashboard is accessible via web browser at http://localhost:8501 It's configured in docker-compose.dev.yml as part of the RustBalancer system","title":"Access"},{"location":"components/dashboard/#docker-setup","text":"dashboard: build: context: ./dashboard dockerfile: Dockerfile ports: - \"8501:8501\" environment: - DEPLOYMENT_URL=http://deployment-agent:${HOST_PORT_HTTP_DEPLOYMENT_AGENT}/stats depends_on: - deployment-agent - redis networks: - rust-network The dashboard automatically fetches and displays the latest data from the deployment agent, providing a comprehensive view of your RustBalancer system's performance.","title":"Docker Setup"},{"location":"components/deployment-agent/","text":"Deployment-Agent Table of Contents Features System Architecture Key Concepts Monitoring and Scaling WebSocket Communication Database Integration Features Dynamic container management with Docker Real-time performance monitoring of containers Automatic scaling based on load and performance metrics WebSocket server for real-time updates Redis integration for persistent storage Sophisticated load balancing algorithm HTTP server for stats and management endpoints System Architecture The system consists of several interconnected modules: Main Application ( main.rs ) Container Management ( container.rs ) Queue Management ( queue.rs ) Performance Monitoring ( stats.rs ) WebSocket Server ( socket.rs ) HTTP Server ( http.rs ) Database Integration ( db.rs ) Modules Main ( main.rs ) Initializes the system, starts the HTTP server and WebSocket server Coordinates all components Container Management ( container.rs ) Handles Docker container operations. Creates, stops, and removes Docker containers Manages container lifecycle Interacts with Docker API Queue Management ( queue.rs ) Manages the queue of active containers and scaling decisions Periodically rebuilds the queue based on current system state Performance Monitoring ( stats.rs ) Collects CPU, memory, network, and availability metrics Calculates performance scores for containers Implements sophisticated algorithms for trend analysis and dynamic thresholds WebSocket Server ( socket.rs ) Provides real-time updates of the container queue to clients Implements WebSocket protocol for bi-directional communication HTTP Server ( http.rs ) Exposes endpoints for retrieving container stats Implements CORS for cross-origin requests Database Integration ( db.rs ) Manages Redis connection Provides methods for storing and retrieving configuration values Key Concepts Container Lifecycle Containers go through several states: INIT: Initial state when a container is created LU (Low Utilization): Container is underutilized MU (Medium Utilization): Container has moderate utilization HU (High Utilization): Container is highly utilized SUNDOWN: Container is marked for removal Performance Scoring Each container receives scores based on: CPU usage Memory usage Network usage Availability (response time) These scores are combined into an overall score that determines the container's utilization category. Monitoring and Scaling The system continuously monitors container performance and makes scaling decisions based on: Average load across all containers Presence of critically loaded containers Current number of active containers vs. desired number Cooldown periods to prevent rapid scaling events Scaling operations include: Creating new containers when load is high Marking containers for removal (SUNDOWN) when load is low WebSocket Communication The WebSocket server provides real-time updates of the container queue to clients. This allows for immediate reflection of system changes in client applications. Database Integration Redis is used for persistent storage of: Container information Configuration values Performance metrics This allows for system state recovery in case of restarts.","title":"Deployment Agent"},{"location":"components/deployment-agent/#deployment-agent","text":"Table of Contents Features System Architecture Key Concepts Monitoring and Scaling WebSocket Communication Database Integration Features Dynamic container management with Docker Real-time performance monitoring of containers Automatic scaling based on load and performance metrics WebSocket server for real-time updates Redis integration for persistent storage Sophisticated load balancing algorithm HTTP server for stats and management endpoints System Architecture The system consists of several interconnected modules: Main Application ( main.rs ) Container Management ( container.rs ) Queue Management ( queue.rs ) Performance Monitoring ( stats.rs ) WebSocket Server ( socket.rs ) HTTP Server ( http.rs ) Database Integration ( db.rs ) Modules Main ( main.rs ) Initializes the system, starts the HTTP server and WebSocket server Coordinates all components Container Management ( container.rs ) Handles Docker container operations. Creates, stops, and removes Docker containers Manages container lifecycle Interacts with Docker API Queue Management ( queue.rs ) Manages the queue of active containers and scaling decisions Periodically rebuilds the queue based on current system state Performance Monitoring ( stats.rs ) Collects CPU, memory, network, and availability metrics Calculates performance scores for containers Implements sophisticated algorithms for trend analysis and dynamic thresholds WebSocket Server ( socket.rs ) Provides real-time updates of the container queue to clients Implements WebSocket protocol for bi-directional communication HTTP Server ( http.rs ) Exposes endpoints for retrieving container stats Implements CORS for cross-origin requests Database Integration ( db.rs ) Manages Redis connection Provides methods for storing and retrieving configuration values Key Concepts Container Lifecycle Containers go through several states: INIT: Initial state when a container is created LU (Low Utilization): Container is underutilized MU (Medium Utilization): Container has moderate utilization HU (High Utilization): Container is highly utilized SUNDOWN: Container is marked for removal Performance Scoring Each container receives scores based on: CPU usage Memory usage Network usage Availability (response time) These scores are combined into an overall score that determines the container's utilization category. Monitoring and Scaling The system continuously monitors container performance and makes scaling decisions based on: Average load across all containers Presence of critically loaded containers Current number of active containers vs. desired number Cooldown periods to prevent rapid scaling events Scaling operations include: Creating new containers when load is high Marking containers for removal (SUNDOWN) when load is low WebSocket Communication The WebSocket server provides real-time updates of the container queue to clients. This allows for immediate reflection of system changes in client applications. Database Integration Redis is used for persistent storage of: Container information Configuration values Performance metrics This allows for system state recovery in case of restarts.","title":"Deployment-Agent"},{"location":"components/redis/","text":"Redis and Redis Insight Redis Redis is a fast, in-memory data store used in this project as a key-value database. It is provided through the redis Docker container and is accessible via the rust-network Docker network. Connecting to Redis Hostname: redis Port: Defined by the ${REDIS_PORT} environment variable Password: No password required Redis Insight Redis Insight is a graphical user interface tool for managing and monitoring Redis databases. Important: Redis Insight is only available in the development environment ( docker-compose.dev.yml ). Accessing Redis Insight Accessible through the browser Port: Defined by the ${REDIS_INSIGHT_PORT} environment variable Connecting to Redis via Redis Insight When connecting Redis Insight to the Redis instance, use the following settings: Hostname: redis (the name of the Redis service in the Docker network) Port: Use the value of ${REDIS_PORT} No authentication required","title":"Redis"},{"location":"components/redis/#redis-and-redis-insight","text":"","title":"Redis and Redis Insight"},{"location":"components/redis/#redis","text":"Redis is a fast, in-memory data store used in this project as a key-value database. It is provided through the redis Docker container and is accessible via the rust-network Docker network.","title":"Redis"},{"location":"components/redis/#connecting-to-redis","text":"Hostname: redis Port: Defined by the ${REDIS_PORT} environment variable Password: No password required","title":"Connecting to Redis"},{"location":"components/redis/#redis-insight","text":"Redis Insight is a graphical user interface tool for managing and monitoring Redis databases. Important: Redis Insight is only available in the development environment ( docker-compose.dev.yml ).","title":"Redis Insight"},{"location":"components/redis/#accessing-redis-insight","text":"Accessible through the browser Port: Defined by the ${REDIS_INSIGHT_PORT} environment variable","title":"Accessing Redis Insight"},{"location":"components/redis/#connecting-to-redis-via-redis-insight","text":"When connecting Redis Insight to the Redis instance, use the following settings: Hostname: redis (the name of the Redis service in the Docker network) Port: Use the value of ${REDIS_PORT} No authentication required","title":"Connecting to Redis via Redis Insight"},{"location":"tutorial/components/","text":"Key Components Understanding the building blocks of a load balancer is essential for effective management. This section breaks down the hardware and software components, giving you a clear picture of how each element contributes to the system's functionality.","title":"Key Components"},{"location":"tutorial/components/#key-components","text":"Understanding the building blocks of a load balancer is essential for effective management. This section breaks down the hardware and software components, giving you a clear picture of how each element contributes to the system's functionality.","title":"Key Components"},{"location":"tutorial/load/","text":"Load Testing Rigorous testing is vital to ensure your load balancer can handle real-world scenarios. Prerequisites Ensure Rust is installed on your system. RustBalancer is running with the following configuration: DOCKER_IMAGE=mxmller/rustybalancer-playground:latest TARGET_PORT=5000 HIGH_LOAD_THRESHOLD=60.0 LOW_LOAD_THRESHOLD=75.0 CRITICAL_LOAD_THRESHOLD=30.0 This configuration means: - A new container starts when the average score reaches 60 - A container is removed if its score falls below 30 - New containers are shut down when the avg score recovers to 75 The test suite has been pulled from Git: Either recursively pulled with submodules when pulling RustBalancer or separately pulled from https://github.com/mxmueller/rustybalancer-test-suite/ If pulled recursively, the repo will be located in ./tests/ Running the Test With RustBalancer running, navigate to ./http-stress Follow the tutorial in the README for detailed instructions Quick Test For a simple test, run: cargo run --release -- http://localhost:2548 15 500 3 This command: - Generates 15 requests per second - Runs for 500 seconds - Has a varying load with a maximum of 3 (considered high) Important Notes Local tests are always limited by the performance of the host's network adapter and operating system. This example will demonstrate: The load suddenly becoming very high New containers starting up to the set maximum number Containers being shut down when the test ends Demo","title":"Load Testing"},{"location":"tutorial/load/#load-testing","text":"Rigorous testing is vital to ensure your load balancer can handle real-world scenarios.","title":"Load Testing"},{"location":"tutorial/load/#prerequisites","text":"Ensure Rust is installed on your system. RustBalancer is running with the following configuration: DOCKER_IMAGE=mxmller/rustybalancer-playground:latest TARGET_PORT=5000 HIGH_LOAD_THRESHOLD=60.0 LOW_LOAD_THRESHOLD=75.0 CRITICAL_LOAD_THRESHOLD=30.0 This configuration means: - A new container starts when the average score reaches 60 - A container is removed if its score falls below 30 - New containers are shut down when the avg score recovers to 75 The test suite has been pulled from Git: Either recursively pulled with submodules when pulling RustBalancer or separately pulled from https://github.com/mxmueller/rustybalancer-test-suite/ If pulled recursively, the repo will be located in ./tests/","title":"Prerequisites"},{"location":"tutorial/load/#running-the-test","text":"With RustBalancer running, navigate to ./http-stress Follow the tutorial in the README for detailed instructions","title":"Running the Test"},{"location":"tutorial/load/#quick-test","text":"For a simple test, run: cargo run --release -- http://localhost:2548 15 500 3 This command: - Generates 15 requests per second - Runs for 500 seconds - Has a varying load with a maximum of 3 (considered high)","title":"Quick Test"},{"location":"tutorial/load/#important-notes","text":"Local tests are always limited by the performance of the host's network adapter and operating system. This example will demonstrate: The load suddenly becoming very high New containers starting up to the set maximum number Containers being shut down when the test ends","title":"Important Notes"},{"location":"tutorial/load/#demo","text":"","title":"Demo"},{"location":"tutorial/setup/","text":"Setup Process The setup process is a crucial first step in implementing a load balancer. These videos guide you through the configuration and deployment of load balancers in various environments, ensuring you start on the right foot. /jobs/setup.sh Read the chapter on How To Setup","title":"Setup Process"},{"location":"tutorial/setup/#setup-process","text":"The setup process is a crucial first step in implementing a load balancer. These videos guide you through the configuration and deployment of load balancers in various environments, ensuring you start on the right foot. /jobs/setup.sh Read the chapter on How To Setup","title":"Setup Process"},{"location":"tutorial/startup/","text":"Starting the System for the First Time When you initiate the system for the first time, it's crucial to exercise patience. Do not proceed until you see the complete queue displayed in the waiting line. This initial loading process may take a few moments, but it's essential for proper system initialization. # for this example the dev variant is used /jobs/run.sh -e dev For more instructions see the How To Setup","title":"Starting the System"},{"location":"tutorial/startup/#starting-the-system-for-the-first-time","text":"When you initiate the system for the first time, it's crucial to exercise patience. Do not proceed until you see the complete queue displayed in the waiting line. This initial loading process may take a few moments, but it's essential for proper system initialization. # for this example the dev variant is used /jobs/run.sh -e dev For more instructions see the How To Setup","title":"Starting the System for the First Time"},{"location":"tutorial/traffic/","text":"High Traffic Behavior Adaptability is at the heart of effective load balancing. These videos demonstrate how load balancers dynamically adjust to changing traffic demands, showcasing their ability to maintain optimal performance as your needs grow or fluctuate. RustBalancer Load Testing Guide Prerequisites Ensure Rust is installed on your system. RustBalancer is running with the following configuration: DOCKER_IMAGE=traefik/whoami TARGET_PORT=80 The test suite has been pulled from Git: Either recursively pulled with submodules when pulling RustBalancer, or separately pulled from https://github.com/mxmueller/rustybalancer-test-suite/ If pulled recursively, the repo will be located in ./tests/ Running the Test With RustBalancer running, navigate to ./http-stress Follow the tutorial in the README for detailed instructions Quick Test For a simple test, run: cargo run --release -- http://localhost:2548 5000 200 0 This command generates 5000 requests per second. The second paramter represents the time duration of the test. The last on has to be null for this setup. Important Note Local tests are always limited by the performance of the host's network adapter and operating system. Demo","title":"High Traffic Behavior"},{"location":"tutorial/traffic/#high-traffic-behavior","text":"Adaptability is at the heart of effective load balancing. These videos demonstrate how load balancers dynamically adjust to changing traffic demands, showcasing their ability to maintain optimal performance as your needs grow or fluctuate.","title":"High Traffic Behavior"},{"location":"tutorial/traffic/#rustbalancer-load-testing-guide","text":"","title":"RustBalancer Load Testing Guide"},{"location":"tutorial/traffic/#prerequisites","text":"Ensure Rust is installed on your system. RustBalancer is running with the following configuration: DOCKER_IMAGE=traefik/whoami TARGET_PORT=80 The test suite has been pulled from Git: Either recursively pulled with submodules when pulling RustBalancer, or separately pulled from https://github.com/mxmueller/rustybalancer-test-suite/ If pulled recursively, the repo will be located in ./tests/","title":"Prerequisites"},{"location":"tutorial/traffic/#running-the-test","text":"With RustBalancer running, navigate to ./http-stress Follow the tutorial in the README for detailed instructions","title":"Running the Test"},{"location":"tutorial/traffic/#quick-test","text":"For a simple test, run: cargo run --release -- http://localhost:2548 5000 200 0 This command generates 5000 requests per second. The second paramter represents the time duration of the test. The last on has to be null for this setup.","title":"Quick Test"},{"location":"tutorial/traffic/#important-note","text":"Local tests are always limited by the performance of the host's network adapter and operating system.","title":"Important Note"},{"location":"tutorial/traffic/#demo","text":"","title":"Demo"}]}